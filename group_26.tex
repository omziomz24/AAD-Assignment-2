% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{article}
\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math} % this also loads fontspec
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else
  % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\usepackage[margin=1in]{geometry}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\usepackage{bookmark}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same}
\hypersetup{
  pdftitle={Group-26 AAD-Assignment-2},
  pdfauthor={Omar, Eloise, Alina, Sue},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}

\title{Group-26 AAD-Assignment-2}
\author{Omar, Eloise, Alina, Sue}
\date{2025-05-13}

\begin{document}
\maketitle

{
\setcounter{tocdepth}{4}
\tableofcontents
}
\section{2.1 Nonlinear model vs non-parametric
model}\label{nonlinear-model-vs-non-parametric-model}

\noindent \large \textbf{GAM:} \normalsize

\noindent \textbf{Pros}

\begin{itemize}
  \item \textbf{Flexibility to capture non-linearity}. In a GAMM we replace each linear term $\beta_{k} x_{k}$ with a smooth function $f_{k}(x_{k})$,     meaning we can automatically model non-linear relationships between each predictor and the response without having to manually try out different      transformation on each variable individually.
  \item \textbf{Non-linear fits may be more accurate}. The ability of creating this non-linear predictor and response relationship may make our model     more accurate when predicting the medianHousingValue.
  \item \textbf{Interperability from additivity}. Since a GAMM is additive, we can examine the effect of each $X_j$ on $Y$ individually while holding      all of the other variables fixed. Therefore, we can understand each variables individual effect on house value.
  \item \textbf{Control over smoothness}. Each $f_j$ comes with an associated smoothing parameter (or degrees of freedom), making it straightforward      to trade bias and variance  (e.g. via cross-validation).
\end{itemize}

\noindent \textbf{Cons}

\begin{itemize}
  \item \textbf{Additivity assumption restriction}. If there are strong synergistic effects like between location (longitude/latitude) and income         \textendash an additive model will not capture them unless explicit interaction terms $X_j \times X_k$ are included or low-dimensional               interactions function of the form $f_{jk}(X_j, X_k)$ are manually introduced. 
  \item \textbf{Computational cost}. Fitting this model to over \textasciitilde$20,600$ observations and multiple smoothers can be very slow when        compared to fitting a single parametric method.
\end{itemize}

\noindent \large \textbf{KNN:} \normalsize

\noindent \textbf{Pros}

\begin{itemize}
  \item \textbf{Completely non-parametric}. KNN makes no assumptions about the form of $f(X)$, allowing the model to potentially fit better than a      parametric model. At a point $x_0$ KNN averages the responses of the $K$ closest training blocks: $\hat{f}(x_{0}) = \frac{1}{K} \sum_{x_{i}           \in N_{0}}{y_i}$, where $N_0$ is the set of the $K$ nearest neighbors.
  \item \textbf{Control of bias-variance}. A small $K$ yields a very flexible, low-bias but high-variance fit; large $K$ yields a smoother,      lower-variance fit.
\end{itemize}

\noindent \textbf{Cons}

\begin{itemize}
  \item \textbf{Dimensoniality constraints}. As the number of predictors grows, the "nearest" neighbors tend to be far away in a high-dimensional       space, so KNN's performance degrades rapidly as the number of predictors grow.
  \item \textbf{Distance metric sensitivity}. With a KNN you must scale the numeric features and encode the categorical features (e.g.                  oceanProximity) carefully. Otherwise poorly scaled or encoded features can dominate the distance of the nearest neighbors calculation.
  \item \textbf{Computationally intensive with predictions}. For each new group of predictions all \textasciitilde$20,600$ must be computed to find     the $K$ nearest, which can be very intensive and slow.
  \item \textbf{Low interperability}. There is no simple way to explain a KNN prediction beyond pointing to the raw neighbors and their average.
\end{itemize}

\noindent \large \textbf{In this housing-price context: } \normalsize

\begin{itemize}
  \item \textbf{GAMM:} it is likely to give an interpretable model with, as we can analyse the partial-effects (e.g. how median income or ocean         proximity individually affects price), and we can capture smooth non-linear trends.
  \item \textbf{KNN:} can capture complex interactions, between predictors, automatically, but with eight predictors (including a categorical     one)   it may run into high-dimensionality issues, making distance-based averaging unstable and slow.
\end{itemize}

\subsection{2.1.1 GAM vs KNN approach}\label{gam-vs-knn-approach}

\subsection{2.1.2 GAM vs KNN Regression
Model}\label{gam-vs-knn-regression-model}

\subsection{2.1.3 Which model performs
better?}\label{which-model-performs-better}

\section{2.2 Classification models}\label{classification-models}

\subsection{2.2.1 Two classification
methods}\label{two-classification-methods}

\subsection{2.2.2 Suggested classifiers}\label{suggested-classifiers}

\subsection{2.2.3 Which classification method performs
better?}\label{which-classification-method-performs-better}

\section{2.3 A hybrid approach}\label{a-hybrid-approach}

\subsection{2.3.1 Dicussing feasibility of the
approach}\label{dicussing-feasibility-of-the-approach}

\subsection{2.3.2 test MSE of medianHousingValue using the
approach}\label{test-mse-of-medianhousingvalue-using-the-approach}

\subsection{2.3.3 Comparison of the accuracy of this procedure to model
in
2.1.3}\label{comparison-of-the-accuracy-of-this-procedure-to-model-in-2.1.3}

\end{document}
